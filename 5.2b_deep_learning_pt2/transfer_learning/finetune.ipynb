{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_hy9iCXlaax"
   },
   "source": [
    "## Transfer Learning on Cats-Dogs Classification - Fine Tune\n",
    "\n",
    "#### Finetune MobileNet-V2 top layers and top model to classify cats vs. dogs.\n",
    "Adapted from https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "\n",
    "### SDSC Summer Institute\n",
    "Mai H. Nguyen, UC San Diego\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NmDHijos0sW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjRHT_7ds0sX",
    "outputId": "67d5215b-c5a4-47fa-ee1e-4f13177ec0c7"
   },
   "outputs": [],
   "source": [
    "print (tf.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nvidia-smi to get GPU device state\n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5OAYvK0s0sX"
   },
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd4JjV5Cs0sX"
   },
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 1234\n",
    "\n",
    "# Disable hash randomization by specifying the value 0.\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set python built-in random generator\n",
    "random.seed(seed)\n",
    "\n",
    "# Set tf global random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set tensorflow graph-level random seed\n",
    "tf.compat.v1.random.set_random_seed(seed)\n",
    "\n",
    "# Potential randomness from CUDNN\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLToN9Hxs0sY"
   },
   "source": [
    "### Set image location and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "USER = os.environ['USER']\n",
    "SLURM_JOBID = os.environ['SLURM_JOBID']\n",
    "\n",
    "data_path = '/scratch/' + USER + '/job_' + SLURM_JOBID + '/catsVsDogs'\n",
    "print (data_path)\n",
    "\n",
    "# Location of images\n",
    "# Set paths for train, validation, and test data\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "print ('Train path:' + train_data_dir)\n",
    "print ('Validation path:' + val_data_dir)\n",
    "print ('Test path:' + test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 224, 224 \n",
    "IMG_SIZE = (img_width,img_height)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Data setup\n",
    "rescale = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "train_datagen      = ImageDataGenerator(shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, preprocessing_function = rescale)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = rescale)\n",
    "\n",
    "# Set up test data generator\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=IMG_SIZE,\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    class_mode='binary', \n",
    "                                                    shuffle = True,\n",
    "                                                    seed = seed)           \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = validation_datagen.flow_from_directory(val_data_dir,\n",
    "                                                              target_size=IMG_SIZE,\n",
    "                                                              batch_size = BATCH_SIZE,\n",
    "                                                              class_mode='binary',\n",
    "                                                              shuffle = False, \n",
    "                                                              seed = seed)\n",
    "# Set up generator to generate batched of test data for model\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=IMG_SIZE,\n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle = False,\n",
    "                                                  seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from feature extraction\n",
    "Load model saved from feature extraction.  Weights in last blocks and top model will be adjusted.  All other weights are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/features_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to list layers in model\n",
    "# print(\"Number of layers in the base model: \", len(model.layers[1].layers))\n",
    "# list(enumerate(model.layers[0].layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freeze all weights of model up to Block 14\n",
    "model.trainable = True\n",
    "fine_tune_start = 116\n",
    "for layer in model.layers[1].layers[:fine_tune_start]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Look at model summary    \n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Compile model with very slow learning rate\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001),\n",
    "              loss= losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "# Perform early stopping to avoid overfitting and ModelCheckpoint to save the best model\n",
    "checkpoint_path = 'tmp/checkpoint'\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001,mode='min'),\n",
    "             ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', mode = 'min', \n",
    "                             save_best_only = True, save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_history = model.fit(train_generator,epochs=EPOCHS, \n",
    "                          validation_data=validation_generator, \n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model that was saved using ModelCheckpoint (from checkpoint_path)\n",
    "# ==> YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights from finetuning\n",
    "# ==> YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation loss\n",
    "fig, axs = plt.subplots(1,2, figsize= (20,5))\n",
    "axs[0].plot(train_history.history['loss'])\n",
    "axs[0].plot(train_history.history['val_loss'])\n",
    "axs[0].set_title(\"Train, Val loss history\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].legend([\"Train Loss\",\"Val Loss\"])\n",
    "\n",
    "# Plot train and validation accuracy\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "axs[1].set_title(\"Train, Val Accuracy history\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend([\"Train Accuracy\",\"Val Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train data accuracy\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "# Get test data accuracy\n",
    "_, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test data accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted value and the ground truth value of test data\n",
    "pred = (model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics for test data\n",
    "print(classification_report(y_true= true, y_pred = pred, target_names=['cats', 'dogs'],digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(img_file):\n",
    "    \"\"\"load individual images\"\"\"\n",
    "    img = load_img(img_file, target_size = (img_width, img_height))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    # img = img_to_array(img) / 255\n",
    "    img = (img_to_array(img)/127.5)-1.0\n",
    "    img = np.expand_dims(img, axis = 0) #model input is (1,150,150,3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1070.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1233.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1080.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "\n",
    "# Print image prediction, rounded to 5 decimal places\n",
    "# ==> YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on dog image 1132\n",
    "# ==> YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1311.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1338.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1342.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1180.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1048.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1342.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "features_final_soln_tfl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
